# -*- coding: utf-8 -*-
"""Dall-E-Voice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qr140hrjjzB1MVgimQ2AG76HJeyq9-J6
"""

'''
exemplary sources:
https://www.youtube.com/watch?v=JYLQwFX8Rek
'''

# !pip install jina
# !pip install SpeechRecognition
# !pip install gTTS
# !pip install playsound

# !pip3 install --upgrade pip

# !pip install --upgrade pip setuptools wheel

# !apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg
# !pip install pyaudio

# !pip install python-pyaudio

server_url = 'grpcs://dalle-flow.dev.jina.ai'

from docarray import Document

import random
import os
import speech_recognition as sr
from playsound import playsound
from gtts import gTTS

r = sr.Recognizer()
mic = sr.Microphone()

def mic_text_doc():
    text = ''
    with mic as m:
        audio = r.listen(m,5,5)
        try:
            text = r.recognize_google(audio,language='en-En')
            print(text)
        except sr.UnknownValueError:
            text_to_speak("your voice is not clear")
    
    return text


def text_to_speak(value):
    tts = gTTS(value,lang='en')
    rand = random.randint(1,1000000)
    file = "voice" + str(rand) + ".mp3"
    tts.save(file)
    playsound(file)
    os.remove(file)

# max example number must be 8 and more example mean it slow down
def my_create(my_text, example_num):
  doc = Document(text=my_text).post(server_url, parameters={'num_images': example_num})
  da = doc.matches
  da.plot_image_sprites(fig_size=(10,10), show_index=True)
  return doc

# For high image quality
def my_clear(examples, exm_indeksi):
  fav = examples.matches[exm_indeksi]
  fav = fav.post(f'{server_url}/upscale')
  fav.display()

# deflection determines how much to differ from the original sample, it is a number in the range [0,1]
# when the deflection is close to 0, different results are obtained from the original sample,
# if the deflection is close to 1, results will be quite similar to the original example
def my_variation(examples, exm_indeksi, exm_num, deflection):
  fav = examples.matches[exm_indeksi]
  fav.embedding = examples.embedding
  diffused = fav.post(f'{server_url}', parameters={'skip_rate': deflection, 'num_images': exm_num}, target_executor='diffusion')
  diffused.matches.plot_image_sprites(fig_size=(10,10), show_index=True)
  return diffused

while True:
    text_to_speak("program is start")
    text = mic_text_doc().lower()
    if 'create' in text:
      text_to_speak("creating")
      a = my_create(text,1)
      text_to_speak("clearing")
      my_clear(a,1)
      text_to_speak("making variant")
      vv = my_variation(a, 1, 8, 0.5)
      text_to_speak("finish")
    elif 'quit' in text:
      text_to_speak("quitting")
      break
    else:
        pass